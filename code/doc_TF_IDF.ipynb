{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 对poem.xlsx中的诗歌进行向前最大匹配分词，词表在wordlist.xlsx中已经给出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：有些字符可能不在词表中（out-of-vocabulary），可以保留这些字符，也可以直接去掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取文件，如有报错，可根据报错信息安装xlrd或者openpyxl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "table = pd.read_excel('poem_v2.xlsx')\n",
    "word_list_df = pd.read_excel('wordlist_v2.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list_df = word_list_df[word_list_df.simple !='一作']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#存储所有分词\n",
    "wl = word_list_df['simple'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算wordlist中词语的最大长度max_length\n",
    "word_list_df['len'] = word_list_df['simple'].apply(len)\n",
    "max_length = word_list_df.sort_values('len', ascending = False).iloc[0, 2]\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分词的过程\n",
    "\n",
    "# 实现前向最大匹配分词算法\n",
    "# string: 待分词的串\n",
    "# word_list: 词表\n",
    "# max_length: 词表中词语的最大长度\n",
    "import string\n",
    "def cut(stri, word_list, max_length):\n",
    "    stri = ''.join(c for c in stri if c not in string.punctuation).replace(' ','')\n",
    "    result = []\n",
    "    cur = stri[:max_length]\n",
    "    while len(stri):\n",
    "        for i in range(max_length+1)[::-1]:\n",
    "            if cur[:i] in word_list:\n",
    "                result.append(cur[:i])\n",
    "                stri = stri[i:]\n",
    "                cur = stri[:max_length]\n",
    "                break\n",
    "            elif i == 1:#如果某个字不在list中直接去除\n",
    "                stri = stri[i:]\n",
    "                cur = stri[:max_length]\n",
    "                break\n",
    "                \n",
    "    return result\n",
    "# 执行分词（可能需要等待几分钟）\n",
    "table['words'] = table['simple'].apply(lambda x: ' '.join(cut(x, wl, max_length)))\n",
    "table.to_csv('wordlist_v3.csv', encoding = 'utf_8_sig', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#直接读取分词结果\n",
    "table = pd.read_csv('wordlist_v3.csv')\n",
    "table1 = table.drop(['content', 'words'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#根据诗歌id输出诗歌得内容\n",
    "def gather(x):\n",
    "    res = []\n",
    "    res.append(x[x.line_number==-100]['simple'].values[0][2:])\n",
    "    res.append(x[x.line_number==-1]['simple'].values[0][2:])\n",
    "    res.extend(list(x[(x.line_number!=-100)&(x.line_number!=-1)]['simple'].values))\n",
    "    return res\n",
    "id_poems = pd.DataFrame(table.groupby('Poem_id').apply(gather))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#根据作者的名字，找出对应的诗歌id\n",
    "author = table1[table1.line_number == -1]\n",
    "author['simple'] = author['simple'].apply(lambda x:x[2:])\n",
    "author_poem_list = author.groupby('simple').apply(lambda x:x['Poem_id'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 统计每个词在文档中的TF-IDF值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：本次作业实现最基础版本的TF-IDF计算即可，不必实现其他变种"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照空格分开，stack\n",
    "split_words = table['words'].str.split(' ', expand=True).stack().rename('word').reset_index()\n",
    "new_data = pd.merge(table['Poem_id'], split_words, left_index=True, right_on='level_0')\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = new_data.loc[:,['word', 'Poem_id']]\n",
    "df_s = df.sort_values('word')\n",
    "df_s1 = df_s[df_s.word != '']\n",
    "#计算tf值\n",
    "df_s1['freq'] = 1\n",
    "df_s2 = pd.DataFrame(df_s1.groupby(['word','Poem_id'])['freq'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#展成向量形式\n",
    "word_vec = df_s2.unstack()\n",
    "word_vec.columns = word_vec.columns.droplevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#计算idf\n",
    "import numpy as np\n",
    "df = word_vec.count(axis = 1)\n",
    "N = word_vec.shape[1]\n",
    "idf = np.log(N/df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tf-idf矩阵\n",
    "#weight = word_vec.apply(lambda x:x*idf)\n",
    "weight = pd.read_csv('weight1.csv', index_col = 'word', engine = 'c', encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#根据分词索引存储过它的诗歌id\n",
    "'''\n",
    "def search1(query):\n",
    "    l = weight.loc[query]\n",
    "    doc = l[l==l].sort_values(ascending = False)\n",
    "    res = doc.index.values\n",
    "    return list(res)\n",
    "\n",
    "df = pd.DataFrame({'word':weight.index.values})\n",
    "def search(x):\n",
    "    return search1(x.word)\n",
    "df['list'] = df.apply(search, axis = 1)\n",
    "df = df.set_index('word')\n",
    "'''\n",
    "#df.to_csv('word_id.csv', encoding = 'utf-8_sig')\n",
    "dataf = pd.read_csv('word_id.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf['doc_freq'] = dataf.apply(lambda x:len(x.list), axis =1)\n",
    "dataf['word_freq'] = df_s2.groupby('word')['freq'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = weight.index.values\n",
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Poem_id</th>\n",
       "      <th>level_0</th>\n",
       "      <th>level_1</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4371</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>饯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4371</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>唐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4371</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>永昌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4371</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>一</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4371</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>作</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200373</th>\n",
       "      <td>39205</td>\n",
       "      <td>46275</td>\n",
       "      <td>4</td>\n",
       "      <td>屏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200374</th>\n",
       "      <td>39205</td>\n",
       "      <td>46276</td>\n",
       "      <td>0</td>\n",
       "      <td>尽日</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200375</th>\n",
       "      <td>39205</td>\n",
       "      <td>46276</td>\n",
       "      <td>1</td>\n",
       "      <td>池边</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200376</th>\n",
       "      <td>39205</td>\n",
       "      <td>46276</td>\n",
       "      <td>2</td>\n",
       "      <td>钓</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200377</th>\n",
       "      <td>39205</td>\n",
       "      <td>46276</td>\n",
       "      <td>3</td>\n",
       "      <td>锦鳞</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200378 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Poem_id  level_0  level_1 word\n",
       "0          4371        0        0    饯\n",
       "1          4371        0        1    唐\n",
       "2          4371        0        2   永昌\n",
       "3          4371        0        3    一\n",
       "4          4371        0        4    作\n",
       "...         ...      ...      ...  ...\n",
       "200373    39205    46275        4    屏\n",
       "200374    39205    46276        0   尽日\n",
       "200375    39205    46276        1   池边\n",
       "200376    39205    46276        2    钓\n",
       "200377    39205    46276        3   锦鳞\n",
       "\n",
       "[200378 rows x 4 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_words = table['words'].str.split(' ', expand=True).stack().rename('word').reset_index()\n",
    "new_data = pd.merge(table['Poem_id'], split_words, left_index=True, right_on='level_0')\n",
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.查询算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#近义词表\n",
    "similar_dict = np.load('similar_dict.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['䌽', '一', '一一', ..., '龙', '龙门', '龟'], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['freq']=1\n",
    "a=new_data.groupby('word')['freq'].sum()\n",
    "target_list = a[a>10].index.values\n",
    "target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(target_list).to_csv('target_list.csv',encoding = 'utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_POEM_SHOWN = 20\n",
    "#查询关键词只有一个\n",
    "def search1(weight, query,similar_dict):\n",
    "    l = weight.loc[query]\n",
    "    doc = l[l==l].sort_values(ascending = False)\n",
    "    res = list(doc.index.values)\n",
    "    num = len(res)\n",
    "    print(num)\n",
    "    #如果符合条件的诗歌太少，进行近义词搜索\n",
    "    if len(res) < MAX_POEM_SHOWN:\n",
    "        similar_d = similar_dict[query]\n",
    "        i = 0\n",
    "        while num < MAX_POEM_SHOWN:\n",
    "            cur_key = similar_d[i][0]\n",
    "            print(cur_key)\n",
    "            l = weight.loc[cur_key]\n",
    "            doc = l[l==l].sort_values(ascending = False)\n",
    "            res.extend(list(doc.index.values))\n",
    "            i+=1\n",
    "            num += len(doc)\n",
    "    return res[:min(20,len(res))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#查询关键词有两个\n",
    "def search2(weight, query_list,similar_dict):    \n",
    "    word1 = query_list[0]\n",
    "    word2 = query_list[1]\n",
    "    l1 = weight.loc[word1]\n",
    "    doc1 = pd.DataFrame(l1[l1==l1]).reset_index()\n",
    "    l2 = weight.loc[word2]\n",
    "    doc2 = pd.DataFrame(l2[l2==l2]).reset_index()\n",
    "\n",
    "    #取交集\n",
    "    alpha = 0.6\n",
    "    intersection = pd.merge(doc1, doc2, on = 'index', how = 'inner')\n",
    "    intersection['weight'] = intersection[word1] * alpha + intersection[word2] * (2-alpha)\n",
    "    intersection = intersection.loc[:,['index', 'weight']]\n",
    "    concat_list = []\n",
    "    if len(intersection)>0:\n",
    "        concat_list.append(intersection)\n",
    "\n",
    "    if len(intersection) < MAX_POEM_SHOWN:\n",
    "        if word1 in target_list:\n",
    "            similar1 = similar_dict[word1][0][0]\n",
    "            similar1_cor = similar_dict[word1][0][1]\n",
    "            l1 = weight.loc[similar1]\n",
    "            doc11 = pd.DataFrame(l1[l1==l1]).reset_index()\n",
    "            intersection1 = pd.merge(doc11, doc2, on = 'index', how = 'inner')\n",
    "            intersection1['weight'] = intersection1[similar1] * similar1_cor * alpha + intersection1[word2] * (2-alpha)\n",
    "            intersection1 = intersection1.loc[:,['index', 'weight']]\n",
    "            if len(intersection)>0:\n",
    "                concat_list.append(intersection1)\n",
    "\n",
    "        if word2 in target_list:\n",
    "            similar2 = similar_dict[word2][0][0]\n",
    "            similar2_cor = similar_dict[word2][0][1]\n",
    "            l2 = weight.loc[similar2]\n",
    "            doc21 = pd.DataFrame(l2[l2==l2]).reset_index()\n",
    "            intersection2 = pd.merge(doc1, doc21, on = 'index', how = 'inner')\n",
    "            intersection2['weight'] = intersection2[word1] *  alpha + intersection2[similar2] * similar2_cor *(2-alpha)\n",
    "            intersection2 = intersection2.loc[:,['index', 'weight']]\n",
    "            if len(intersection)>0:\n",
    "                concat_list.append(intersection2)\n",
    "\n",
    "\n",
    "    union = pd.merge(doc1, doc2, on = 'index', how = 'outer')\n",
    "    left = union.append(intersection).drop_duplicates(keep = False)\n",
    "    left['weight'] = left.apply(lambda x: x.iloc[1] if x.iloc[1] == x.iloc[1] else x.iloc[2], axis = 1)\n",
    "    left = left.loc[:,['index','weight']]\n",
    "    concat_list.append(left)\n",
    "    concat = pd.concat(concat_list).drop_duplicates('index')\n",
    "    concat = concat.sort_values('weight', ascending = False)\n",
    "    return concat['index'].values[:min(len(concat),20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查询关键词有三个\n",
    "def search3(weight, query,similar_dict):\n",
    "    word1 = query_list[0]\n",
    "    word2 = query_list[1]\n",
    "    word3 = query_list[2]\n",
    "    l1 = weight.loc[word1]\n",
    "    doc1 = pd.DataFrame(l1[l1==l1]).reset_index()\n",
    "    l2 = weight.loc[word2]\n",
    "    doc2 = pd.DataFrame(l2[l2==l2]).reset_index()\n",
    "    l3 = weight.loc[word3]\n",
    "    doc3 = pd.DataFrame(l3[l3==l3]).reset_index()\n",
    "\n",
    "    #取三个关键词的交集\n",
    "    intersection1 = pd.merge(doc1, doc2, on = 'index', how = 'inner')\n",
    "    intersection2 = pd.merge(doc1, doc3, on = 'index', how = 'inner')\n",
    "    intersection3 = pd.merge(doc2, doc3, on = 'index', how = 'inner')\n",
    "\n",
    "    intersection = pd.merge(intersection1, doc3, on = 'index', how = 'inner')\n",
    "    concat_list = []\n",
    "    alpha = 1.1\n",
    "    beta=1\n",
    "    intersection['weight'] = intersection[word1] * alpha + intersection[word2] * beta + intersection[word3] * (3-alpha-beta)\n",
    "    concat_list = []\n",
    "    intersection=intersection.loc[:,['index','weight']]\n",
    "    concat_list.append(intersection)\n",
    "    \n",
    "    #只包含两个关键词的集合\n",
    "    left1 = intersection1.append(intersection).drop_duplicates(keep = False)\n",
    "    left1['weight'] = left1.apply(lambda x: alpha*x.iloc[1]+(2-alpha)*x.iloc[2] if x.weight != x.weight else x.iloc[3], axis = 1)\n",
    "    left1 = left1.loc[:,['index','weight']]\n",
    "\n",
    "    left2 = intersection2.append(intersection).drop_duplicates(keep = False)\n",
    "    left2['weight'] = left2.apply(lambda x: alpha*x.iloc[1]+(2-alpha)*x.iloc[2] if x.weight != x.weight else x.iloc[3], axis = 1)\n",
    "    left2 = left2.loc[:,['index','weight']]\n",
    "\n",
    "    left3 = intersection3.append(intersection).drop_duplicates(keep = False)\n",
    "    left3['weight'] = left3.apply(lambda x: alpha*x.iloc[1]+(2-alpha)*x.iloc[2] if x.weight != x.weight else x.iloc[3], axis = 1)\n",
    "    left3 = left3.loc[:,['index','weight']]\n",
    "    \n",
    "    #关键词替换：只替换一个\n",
    "    if len(intersection) < MAX_POEM_SHOWN:\n",
    "        if len(intersection1) >0 and word3 in target_list:\n",
    "            similar3 = similar_dict[word3][0][0]\n",
    "            similar3_cor = similar_dict[word3][0][1]\n",
    "            l31 = weight.loc[similar3]\n",
    "            doc31 = pd.DataFrame(l31[l31==l31]).reset_index()\n",
    "            intersection31 = pd.merge(intersection1, doc31, on = 'index', how = 'inner')\n",
    "            intersection31['weight'] = intersection31[word1] * alpha+intersection31[word2]* beta +intersection31[similar3]* (3-alpha-beta)*similar3_cor\n",
    "            intersection31=intersection31.loc[:,['index','weight']]\n",
    "            concat_list.append(intersection31)\n",
    "        if len(intersection2) >0 and word2 in target_list:\n",
    "            similar2 = similar_dict[word2][0][0]\n",
    "            similar2_cor = similar_dict[word2][0][1]\n",
    "            l21 = weight.loc[similar2]\n",
    "            doc21 = pd.DataFrame(l21[l21==l21]).reset_index()\n",
    "            intersection21 = pd.merge(intersection2, doc21, on = 'index', how = 'inner')\n",
    "            intersection21['weight'] = intersection21[word1]*alpha+intersection21[similar2]*beta*similar2_cor +intersection21[word3]*(3-alpha-beta)\n",
    "            intersection21=intersection21.loc[:,['index','weight']]\n",
    "            concat_list.append(intersection21)\n",
    "        if len(intersection3) >0 and word1 in target_list:\n",
    "            similar1 = similar_dict[word1][0][0]\n",
    "            similar1_cor = similar_dict[word1][0][1]\n",
    "            l11 = weight.loc[similar1]\n",
    "            doc11 = pd.DataFrame(l11[l11==l11]).reset_index()\n",
    "            intersection11 = pd.merge(intersection3, doc11, on = 'index', how = 'inner')\n",
    "            intersection11['weight'] = intersection11[similar1]*alpha*similar1_cor+intersection11[word2]* beta +intersection11[word3]* (3-alpha-beta)\n",
    "            intersection11=intersection11.loc[:,['index','weight']]\n",
    "            concat_list.append(intersection11)\n",
    "    concat_list.extend([left1,left2,left3])\n",
    "    res = pd.concat(concat_list).sort_values('weight', ascending = False)\n",
    "    return res['index'].values[:min(len(res),20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#输入关键词字符串\n",
    "def query_word(weight, query_list,similar_dict):  \n",
    "    if len(query_list) == 1:\n",
    "        ret = search1(weight, query_list[0],similar_dict)\n",
    "    elif len(query_list) == 2:\n",
    "        ret = search2(weight, query_list,similar_dict)\n",
    "    elif len(query_list) == 3:\n",
    "        ret = search3(weight, query_list,similar_dict)\n",
    "    else:\n",
    "        ret = 'too many words'\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['18933', '34102', '29603', '34102', '10950', '29603', '34102',\n",
       "       '10950', '10950', '10950', '29603', '34102', '29603', '29127',\n",
       "       '22530', '22312', '30089', '18294', '20385', '29603'], dtype=object)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_word(weight,['夜', '明月', '一'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
